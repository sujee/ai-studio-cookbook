{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izmeeJoOrkTt"
      },
      "source": [
        "# Run models on Nebius AI Studio (via aisuite API)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nebius/ai-studio-cookbook/blob/main/api/api_aisuite.ipynb)\n",
        "[![](https://img.shields.io/badge/Powered%20by-Nebius-orange?style=flat&labelColor=darkblue&color=orange)](https://nebius.com/ai-studio)\n",
        "\n",
        "## References and Acknoledgements\n",
        "\n",
        "- [API documentation](https://docs.nebius.com/studio/inference/integrations/aisuite)\n",
        "- [aisuite](https://github.com/andrewyng/aisuite)\n",
        "\n",
        "## Pre requisites\n",
        "\n",
        "- Nebius API key.  Sign up for free at [AI Studio](https://studio.nebius.com/)\n",
        "- And complete [the setup](https://github.com/nebius/ai-studio-cookbook/blob/main/setup-dev-env.md)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNJ-WCDSEy0G"
      },
      "source": [
        "## 1 - Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTElVQApE9I7",
        "outputId": "545945e2-891a-42ef-bd1f-43144ec79e62"
      },
      "outputs": [],
      "source": [
        "!pip install openai aisuite  docstring-parser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xp6woeSsFGo5"
      },
      "source": [
        "## 2 - Load Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFSX16IeFLKa",
        "outputId": "40304ba1-036f-4e79-b836-2b706a9a1bcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NOT running in Colab\n",
            "✅ NEBIUS_API_KEY found\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "\n",
        "## Recommended way of getting configuration\n",
        "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
        "   print(\"Running in Colab\")\n",
        "   from google.colab import userdata\n",
        "   NEBIUS_API_KEY = userdata.get('NEBIUS_API_KEY')\n",
        "else:\n",
        "   print(\"NOT running in Colab\")\n",
        "   from dotenv import load_dotenv\n",
        "   this_dir = os.path.abspath('')\n",
        "   parent_dir = os.path.dirname(this_dir)\n",
        "   sys.path.append (os.path.abspath (parent_dir))\n",
        "   load_dotenv()\n",
        "   NEBIUS_API_KEY = os.getenv('NEBIUS_API_KEY')\n",
        "\n",
        "## quick hack (not recommended) - you can hardcode the config key here\n",
        "# NEBIUS_API_KEY = \"your_key_here\"\n",
        "\n",
        "if NEBIUS_API_KEY:\n",
        "  print ('✅ NEBIUS_API_KEY found')\n",
        "  os.environ['NEBIUS_API_KEY'] = NEBIUS_API_KEY\n",
        "else:\n",
        "  raise RuntimeError ('❌ NEBIUS_API_KEY NOT found')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3vB3EdQGnLX"
      },
      "source": [
        "## 3 - Pick a Model\n",
        "\n",
        "1. Go to **models** tab in [studio.nebius.com](https://studio.nebius.com/)\n",
        "2. Copy the model name.  For example **`meta-llama/Llama-3.3-70B-Instruct`**\n",
        "\n",
        "![](https://raw.githubusercontent.com/nebius/ai-studio-cookbook/main/images/ai-studio-1-models.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4 - Run the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8htBO7iH6-e",
        "outputId": "f5280299-a087-4708-c1dc-4c2f5669bf08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----model answer -----\n",
            "The capital of France is Paris.\n",
            "\n",
            "----- full response ----\n",
            "{\n",
            "  \"id\": \"chatcmpl-1bf2820b280f4e8b96e43011da4bbec4\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": \"The capital of France is Paris.\",\n",
            "        \"refusal\": null,\n",
            "        \"role\": \"assistant\",\n",
            "        \"audio\": null,\n",
            "        \"function_call\": null,\n",
            "        \"tool_calls\": [],\n",
            "        \"reasoning_content\": null\n",
            "      },\n",
            "      \"stop_reason\": null\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1749774832,\n",
            "  \"model\": \"meta-llama/Llama-3.3-70B-Instruct\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"service_tier\": null,\n",
            "  \"system_fingerprint\": null,\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 8,\n",
            "    \"prompt_tokens\": 48,\n",
            "    \"total_tokens\": 56,\n",
            "    \"completion_tokens_details\": null,\n",
            "    \"prompt_tokens_details\": null\n",
            "  },\n",
            "  \"prompt_logprobs\": null\n",
            "}\n",
            "---------\n",
            "CPU times: user 34.2 ms, sys: 1.8 ms, total: 36 ms\n",
            "Wall time: 944 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "import os\n",
        "import aisuite as ai\n",
        "\n",
        "client = ai.Client()\n",
        "\n",
        "provider = \"nebius\"\n",
        "model_id = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a helpful assistant.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"What is the capital of France?\"\n",
        "    },\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=f\"{provider}:{model_id}\",\n",
        "    messages=messages,\n",
        ")\n",
        "\n",
        "print ('----model answer -----')\n",
        "print (response.choices[0].message.content)\n",
        "print ('\\n----- full response ----')\n",
        "print(response.to_json())\n",
        "print ('---------')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5 - Try Your Queries\n",
        "\n",
        "Go ahead and experiment with your queries.  Here are some to get you started.\n",
        "\n",
        "> Write python code to read a csv file\n",
        "\n",
        "> write a haiku about cats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "studio-1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

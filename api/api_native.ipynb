{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcmOx48JqtWq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izmeeJoOrkTt"
      },
      "source": [
        "# Run models on Nebius AI Studio (Native)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nebius/ai-studio-cookbook/blob/main/api/api_native.ipynb)\n",
        "[![](https://img.shields.io/badge/Powered%20by-Nebius-orange?style=flat&labelColor=darkblue&color=orange)](https://nebius.com/ai-studio)\n",
        "\n",
        "This the recommended API.  The API uses OpenAI library.\n",
        "\n",
        "## References and Acknowledgements\n",
        "\n",
        "- [API documentation](https://docs.nebius.com/studio/inference/quickstart)\n",
        "\n",
        "## Pre requisites\n",
        "\n",
        "- Nebius API key.  Sign up for free at [AI Studio](https://studio.nebius.com/)\n",
        "- And complete [the setup](https://github.com/nebius/ai-studio-cookbook/blob/main/setup-dev-env.md)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNJ-WCDSEy0G"
      },
      "source": [
        "## 1 - Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTElVQApE9I7",
        "outputId": "545945e2-891a-42ef-bd1f-43144ec79e62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /home/sujee/apps/anaconda3/envs/studio-1/lib/python3.11/site-packages (1.86.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /home/sujee/apps/anaconda3/envs/studio-1/lib/python3.11/site-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /home/sujee/apps/anaconda3/envs/studio-1/lib/python3.11/site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /home/sujee/apps/anaconda3/envs/studio-1/lib/python3.11/site-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /home/sujee/apps/anaconda3/envs/studio-1/lib/python3.11/site-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/sujee/apps/anaconda3/envs/studio-1/lib/python3.11/site-packages (from openai) (2.11.5)\n",
            "Requirement already satisfied: sniffio in /home/sujee/apps/anaconda3/envs/studio-1/lib/python3.11/site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /home/sujee/apps/anaconda3/envs/studio-1/lib/python3.11/site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/sujee/apps/anaconda3/envs/studio-1/lib/python3.11/site-packages (from openai) (4.14.0)\n",
            "Requirement already satisfied: idna>=2.8 in /home/sujee/apps/anaconda3/envs/studio-1/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /home/sujee/apps/anaconda3/envs/studio-1/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /home/sujee/apps/anaconda3/envs/studio-1/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /home/sujee/apps/anaconda3/envs/studio-1/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /home/sujee/apps/anaconda3/envs/studio-1/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /home/sujee/apps/anaconda3/envs/studio-1/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /home/sujee/apps/anaconda3/envs/studio-1/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xp6woeSsFGo5"
      },
      "source": [
        "## 2 - Load Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFSX16IeFLKa",
        "outputId": "40304ba1-036f-4e79-b836-2b706a9a1bcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NOT running in Colab\n",
            "✅ NEBIUS_API_KEY found\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "\n",
        "## Recommended way of getting configuration\n",
        "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
        "   print(\"Running in Colab\")\n",
        "   from google.colab import userdata\n",
        "   NEBIUS_API_KEY = userdata.get('NEBIUS_API_KEY')\n",
        "else:\n",
        "   print(\"NOT running in Colab\")\n",
        "\n",
        "   from dotenv import load_dotenv\n",
        "\n",
        "   this_dir = os.path.abspath('')\n",
        "   parent_dir = os.path.dirname(this_dir)\n",
        "   sys.path.append (os.path.abspath (parent_dir))\n",
        "\n",
        "   load_dotenv()\n",
        "   NEBIUS_API_KEY = os.getenv('NEBIUS_API_KEY')\n",
        "\n",
        "\n",
        "## quick hack (not recommended) - you can hardcode the config key here\n",
        "# NEBIUS_API_KEY = \"your_key_here\"\n",
        "\n",
        "if NEBIUS_API_KEY:\n",
        "  print ('✅ NEBIUS_API_KEY found')\n",
        "  os.environ['NEBIUS_API_KEY'] = NEBIUS_API_KEY\n",
        "else:\n",
        "  raise RuntimeError ('❌ NEBIUS_API_KEY NOT found')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3vB3EdQGnLX"
      },
      "source": [
        "## 3 - Pick a Model\n",
        "\n",
        "1. Go to **models** tab in [studio.nebius.com](https://studio.nebius.com/)\n",
        "2. Copy the model name.  For example **`meta-llama/Llama-3.3-70B-Instruct`**\n",
        "\n",
        "![](https://raw.githubusercontent.com/nebius/ai-studio-cookbook/main/images/ai-studio-1-models.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4 - Run the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8htBO7iH6-e",
        "outputId": "f5280299-a087-4708-c1dc-4c2f5669bf08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----model answer -----\n",
            "The capital of France is Paris.\n",
            "\n",
            "----- full response ----\n",
            "{\n",
            "  \"id\": \"chatcmpl-63389412978f496fb8ed9d5d9e32331e\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": \"The capital of France is Paris.\",\n",
            "        \"refusal\": null,\n",
            "        \"role\": \"assistant\",\n",
            "        \"audio\": null,\n",
            "        \"function_call\": null,\n",
            "        \"tool_calls\": [],\n",
            "        \"reasoning_content\": null\n",
            "      },\n",
            "      \"stop_reason\": null\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1749795342,\n",
            "  \"model\": \"meta-llama/Llama-3.3-70B-Instruct\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"service_tier\": null,\n",
            "  \"system_fingerprint\": null,\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 8,\n",
            "    \"prompt_tokens\": 42,\n",
            "    \"total_tokens\": 50,\n",
            "    \"completion_tokens_details\": null,\n",
            "    \"prompt_tokens_details\": null\n",
            "  },\n",
            "  \"prompt_logprobs\": null\n",
            "}\n",
            "---------\n",
            "CPU times: user 421 ms, sys: 52.8 ms, total: 474 ms\n",
            "Wall time: 1.71 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=\"https://api.studio.nebius.com/v1/\",\n",
        "    api_key=NEBIUS_API_KEY,\n",
        ")\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model = \"meta-llama/Llama-3.3-70B-Instruct\",\n",
        "  messages=[\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"What is the capital of France?\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0.6\n",
        ")\n",
        "\n",
        "print ('----model answer -----')\n",
        "print (completion.choices[0].message.content)\n",
        "print ('\\n----- full response ----')\n",
        "print(completion.to_json())\n",
        "print ('---------')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5 - Try a Reasoning Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5KlDwxJjhEX",
        "outputId": "0aaeb48f-3efa-4cb1-dc1b-b4758bab81f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<think>\n",
            "Okay, the user is asking about my capabilities. I need to provide a clear and comprehensive answer. Let me start by recalling the main functions I can perform.\n",
            "\n",
            "First, I can answer questions across various topics. That includes general knowledge, science, technology, culture, etc. I should mention that I can handle both simple and complex queries.\n",
            "\n",
            "Next, I can write different types of texts. Like articles, stories, emails, scripts, and more. Maybe give examples to make it concrete.\n",
            "\n",
            "Then there's the coding aspect. I can write and explain code in multiple programming languages. It's important to note that I can help with debugging as well.\n",
            "\n",
            "I should also mention my multilingual support. I can communicate in many languages, which is useful for international users.\n",
            "\n",
            "Another point is logical reasoning and problem-solving. I can tackle math problems, analyze data, and provide structured solutions.\n",
            "\n",
            "I need to highlight my ability to engage in meaningful conversations, maintaining context over multiple exchanges. This is good for ongoing discussions.\n",
            "\n",
            "Wait, the user might also be interested in how I handle specific tasks. Maybe include examples like creating summaries, generating ideas, or helping with learning.\n",
            "\n",
            "I should avoid technical jargon and keep the explanation user-friendly. Also, make sure to mention that while I have extensive knowledge, there might be limitations, and I can't access real-time data.\n",
            "\n",
            "Let me structure this into clear sections: answering questions, text creation, coding, multilingual support, logical reasoning, conversation maintenance, and examples of tasks. Conclude by inviting the user to ask for specific help.\n",
            "\n",
            "Check for any missing points. Oh, maybe mention that I can assist with creative tasks too, like writing stories or poems. Also, note that I can explain concepts in simple terms.\n",
            "\n",
            "Make sure the response is friendly and encourages the user to ask for assistance. Avoid making it too long, but cover all key areas.\n",
            "</think>\n",
            "\n",
            "I am Qwen, a large-scale language model developed by Alibaba Group. My capabilities include:\n",
            "\n",
            "1. **Answering Questions**: I can provide information and insights on a wide range of topics, from general knowledge to specialized fields like science, technology, and culture. I can handle both simple and complex queries.\n",
            "\n",
            "2. **Text Creation**: I can generate various types of texts, such as articles, stories, emails, scripts, and more. Whether you need creative writing, academic essays, or business documents, I can assist.\n",
            "\n",
            "3. **Coding**: I can write and explain code in multiple programming languages (e.g., Python, Java, JavaScript). I can also help with debugging and optimizing code.\n",
            "\n",
            "4. **Multilingual Support**: I can communicate in many languages, including but not limited to English, Chinese, Spanish, French, and more, making it accessible to a global audience.\n",
            "\n",
            "5. **Logical Reasoning and Problem-Solving**: I can tackle mathematical problems, analyze data, and provide structured solutions. My reasoning capabilities extend to logical puzzles, algorithm design, and more.\n",
            "\n",
            "6. **Conversational Engagement**: I can maintain context over multiple exchanges, enabling natural and meaningful conversations. This is useful for ongoing discussions, brainstorming, or collaborative problem-solving.\n",
            "\n",
            "7. **Task-Specific Assistance**: I can help with tasks like creating summaries, generating ideas, learning new concepts, and providing step-by-step explanations.\n",
            "\n",
            "**Examples of Tasks**:\n",
            "- Writing a persuasive essay or a creative story.\n",
            "- Explaining complex concepts in simple terms.\n",
            "- Debugging a piece of code or suggesting improvements.\n",
            "- Translating text between languages.\n",
            "- Solving math problems or logical puzzles.\n",
            "\n",
            "While I have extensive knowledge, I don't have access to real-time data or external systems. If you have a specific task or question, feel free to ask, and I'll do my best to assist! 😊\n",
            "----------\n",
            "CPU times: user 7.37 ms, sys: 282 μs, total: 7.65 ms\n",
            "Wall time: 6.91 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# try another model\n",
        "completion = client.chat.completions.create(\n",
        "  model = \"Qwen/Qwen3-30B-A3B\", # this is a reasoning model\n",
        "  messages=[\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\"\"What are your capabilities?\"\"\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0.6\n",
        ")\n",
        "\n",
        "print (completion.choices[0].message.content)\n",
        "print ('----------')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6 - Try Your Queries\n",
        "\n",
        "Go ahead and experiment with your queries.  Here are some to get you started.\n",
        "\n",
        "> Write python code to read a csv file\n",
        "\n",
        "> write a haiku about cats"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "studio-1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

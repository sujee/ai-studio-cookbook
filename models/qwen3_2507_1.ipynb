{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izmeeJoOrkTt"
      },
      "source": [
        "# Run Qwen3-2507 model on Nebius AI Studio\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nebius/ai-studio-cookbook/blob/main/models/qwen3_2507_1.ipynb)\n",
        "[![](https://img.shields.io/badge/Powered%20by-Nebius-orange?style=flat&labelColor=darkblue&color=orange)](https://nebius.com/ai-studio)\n",
        "\n",
        "**Qwen/Qwen3-235B-A22B-2507** model is a top performing open source model.  It comes in 'thinking' and 'instruct' variants.  Use this notebook to run this model on Nebius AI Studio.\n",
        "\n",
        "[Read more here](https://github.com/nebius/ai-studio-cookbook/blob/main/models/qwen3-2507.md)\n",
        "\n",
        "## References\n",
        "\n",
        "- Model card for instruct version: [Qwen/Qwen3-235B-A22B-Instruct-2507](https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507)\n",
        "- Model card for thinking version: [Qwen/Qwen3-235B-A22B-Thinking-2507](https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507)\n",
        "- [Nebius AI Studio](https://studio.nebius.com/)\n",
        "\n",
        "## Pre requisites\n",
        "\n",
        "- Nebius API key.  Sign up for free at [AI Studio](https://studio.nebius.com/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3KSn4LIvFo0"
      },
      "source": [
        "## 1 - Getting Started\n",
        "\n",
        "### 1.1 - Get your Nebius API key at [Nebius AI Studio](https://studio.nebius.com/)\n",
        "\n",
        "### 1.2 - If running on Google Colab ...\n",
        "\n",
        "Add `NEBIUS_API_KEY` to **Secrets** panel on the left as follows\n",
        "\n",
        "![](https://github.com/nebius/ai-studio-cookbook/raw/main/images/google-colab-1.png)\n",
        "\n",
        "\n",
        "### 1.3 - If running locally\n",
        "\n",
        "Create an `.env` file with NEBIUS_API_KEY as follows\n",
        "\n",
        "```text\n",
        "NEBIUS_API_KEY=your_api_key_goes_here\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNJ-WCDSEy0G"
      },
      "source": [
        "## 2 - Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OTElVQApE9I7"
      },
      "outputs": [],
      "source": [
        "%pip install -q openai python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xp6woeSsFGo5"
      },
      "source": [
        "## 2 - Load Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFSX16IeFLKa",
        "outputId": "376e338d-8f14-41a0-8124-91400d3d5e28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Colab\n",
            "âœ… NEBIUS_API_KEY found\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "\n",
        "## Recommended way of getting configuration\n",
        "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
        "   print(\"Running in Colab\")\n",
        "   from google.colab import userdata\n",
        "   NEBIUS_API_KEY = userdata.get('NEBIUS_API_KEY')\n",
        "else:\n",
        "   print(\"NOT running in Colab\")\n",
        "\n",
        "   from dotenv import load_dotenv\n",
        "   load_dotenv()\n",
        "   NEBIUS_API_KEY = os.getenv('NEBIUS_API_KEY')\n",
        "\n",
        "\n",
        "## quick hack (not recommended) - you can hardcode the config key here\n",
        "# NEBIUS_API_KEY = \"your_key_here\"\n",
        "\n",
        "if NEBIUS_API_KEY:\n",
        "  print ('âœ… NEBIUS_API_KEY found')\n",
        "  os.environ['NEBIUS_API_KEY'] = NEBIUS_API_KEY\n",
        "else:\n",
        "  raise RuntimeError ('âŒ NEBIUS_API_KEY NOT found')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smYPQAlBtgTQ"
      },
      "source": [
        "## 3 - Run the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c67AElPbzP7z"
      },
      "source": [
        "### 3.1 - Initialize the client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Bx3BAsiIxfqi"
      },
      "outputs": [],
      "source": [
        "## Create a client\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=\"https://api.studio.nebius.com/v1/\",\n",
        "    api_key=os.environ.get('NEBIUS_API_KEY')\n",
        ")\n",
        "\n",
        "## Select a model\n",
        "MODEL_NAME = \"Qwen/Qwen3-235B-A22B-Instruct-2507\" # this is an instruct model\n",
        "#MODEL_NAME = \"Qwen/Qwen3-235B-A22B-Thinking-2507\" # this is a thinking model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbKjxJndzT6r"
      },
      "source": [
        "### 3.2 - Find out the model's capabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1gN-e3Iw9H3",
        "outputId": "688657b6-f4d2-4eb5-f73e-59663b14b223"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----model answer -----\n",
            "Hello! ðŸ˜Š I'm Qwen, and I'd love to tell you about what I can do! Think of me as your helpful digital friend who's really good with words and problem-solving. Here are some of the things I can help with:\n",
            "\n",
            "I can chat about all sorts of topics - from science and tech to arts and culture. Need help writing a story, an email, or even a poem? I'm your buddy! I can also tackle tricky math problems, help with coding (I know quite a few programming languages!), and break down complex concepts into easier-to-understand bits.\n",
            "\n",
            "When it comes to languages, I'm pretty versatile - I can communicate in over 100 languages, so whether you're speaking English, Chinese, or many other languages, we can chat comfortably.\n",
            "\n",
            "I'm also quite the creative thinker! Need help brainstorming ideas, solving puzzles, or working through logical challenges? I love doing that! Plus, I can help analyze information and data to find useful insights.\n",
            "\n",
            "One thing I'm particularly excited about is my ability to adapt to different situations - whether you need a quick answer or want to dive deep into a topic with step-by-step explanations, I can adjust to your needs.\n",
            "\n",
            "I'm always eager to learn and help, so if you have any questions or need assistance with something, just let me know! What would you like to explore together? ðŸŒŸ\n",
            "CPU times: user 670 ms, sys: 90.3 ms, total: 760 ms\n",
            "Wall time: 5.43 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model = MODEL_NAME,\n",
        "  messages=[\n",
        "      {\n",
        "          \"role\": \"system\",\n",
        "          \"content\": \"You are a helpful AI assistant\"\n",
        "      },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"What are your capabilities?\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0.6\n",
        ")\n",
        "\n",
        "print ('----model answer -----')\n",
        "print (completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfeT8JxlzaNm"
      },
      "source": [
        "### 3.3 - Ask a factual question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8htBO7iH6-e",
        "outputId": "77f1a4e8-e5bd-4db5-9252-3bd6badeb235"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----model answer -----\n",
            "The capital of France is Paris.\n",
            "\n",
            "----- full response ----\n",
            "{\n",
            "  \"id\": \"chatcmpl-4602827c7aa243ffbd27dcf2492c7d3b\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": \"The capital of France is Paris.\",\n",
            "        \"refusal\": null,\n",
            "        \"role\": \"assistant\",\n",
            "        \"annotations\": null,\n",
            "        \"audio\": null,\n",
            "        \"function_call\": null,\n",
            "        \"tool_calls\": [],\n",
            "        \"reasoning_content\": null\n",
            "      },\n",
            "      \"stop_reason\": null\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1754513699,\n",
            "  \"model\": \"Qwen/Qwen3-235B-A22B-Instruct-2507\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"service_tier\": null,\n",
            "  \"system_fingerprint\": null,\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 8,\n",
            "    \"prompt_tokens\": 26,\n",
            "    \"total_tokens\": 34,\n",
            "    \"completion_tokens_details\": null,\n",
            "    \"prompt_tokens_details\": null\n",
            "  },\n",
            "  \"prompt_logprobs\": null,\n",
            "  \"kv_transfer_params\": null\n",
            "}\n",
            "---------\n",
            "CPU times: user 7.17 ms, sys: 46 Âµs, total: 7.21 ms\n",
            "Wall time: 318 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model = MODEL_NAME,\n",
        "  messages=[\n",
        "      {\n",
        "          \"role\": \"system\",\n",
        "          \"content\": \"You are a helpful AI assistant\"\n",
        "      },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"What is the capital of France?\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0.6\n",
        ")\n",
        "\n",
        "print ('----model answer -----')\n",
        "print (completion.choices[0].message.content)\n",
        "print ('\\n----- full response ----')\n",
        "print(completion.to_json())\n",
        "print ('---------')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yp2JEfLYzgEC"
      },
      "source": [
        "### 3.4 - Ask a reasoning question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5KlDwxJjhEX",
        "outputId": "337c7b7f-dbc5-4251-e165-af5e756859fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To compare **9.9** and **9.11**, let's write them with the same number of decimal places to make the comparison easier.\n",
            "\n",
            "- **9.9** is the same as **9.90**\n",
            "- **9.11** stays as **9.11**\n",
            "\n",
            "Now compare:\n",
            "\n",
            "- **9.90** vs **9.11**\n",
            "\n",
            "Look at the digits after the decimal point:\n",
            "- 9.90 has **90** hundredths\n",
            "- 9.11 has **11** hundredths\n",
            "\n",
            "Since **90 > 11**, it follows that:\n",
            "\n",
            "ðŸ‘‰ **9.90 > 9.11**\n",
            "\n",
            "Therefore, **9.9 is bigger than 9.11**.\n",
            "\n",
            "âœ… Final answer: **9.9** is bigger.\n",
            "----------\n",
            "CPU times: user 8.16 ms, sys: 250 Âµs, total: 8.41 ms\n",
            "Wall time: 2.61 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# try another model\n",
        "completion = client.chat.completions.create(\n",
        "  model = MODEL_NAME,\n",
        "  messages=[\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Which is bigger, 9.9 or 9.11?\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0.6\n",
        ")\n",
        "\n",
        "print (completion.choices[0].message.content)\n",
        "print ('----------')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7JaLormtgTR"
      },
      "source": [
        "## 5 - Try Your Queries\n",
        "\n",
        "Go ahead and experiment with your queries.  Here are some to get you started.\n",
        "\n",
        "> Write python code to read a csv file\n",
        "\n",
        "> write a haiku about cats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "poXPoPfOzomP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "studio-cookbook-1",
      "language": "python",
      "name": "studio-cookbook-1"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}